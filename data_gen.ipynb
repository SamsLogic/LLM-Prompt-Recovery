{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-26T18:46:50.998385Z","iopub.status.busy":"2024-03-26T18:46:50.997763Z","iopub.status.idle":"2024-03-26T18:47:04.776000Z","shell.execute_reply":"2024-03-26T18:47:04.775207Z","shell.execute_reply.started":"2024-03-26T18:46:50.998351Z"},"trusted":true},"outputs":[],"source":["import sys \n","from gemma.config import GemmaConfig, get_config_for_7b, get_config_for_2b\n","from gemma.model import GemmaForCausalLM\n","from gemma.tokenizer import Tokenizer\n","import contextlib\n","import os\n","import torch\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","# seed = 42\n","import random\n","# # set seed for reproducibility\n","# torch.manual_seed(seed)"]},{"cell_type":"markdown","metadata":{},"source":["## Load 7B-it Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Load the model\n","# VARIANT = \"7b-it\" \n","# MACHINE_TYPE = \"cuda\" \n","# weights_dir = f'D:\\LLMs\\gemma-{VARIANT}-weights' \n","\n","# @contextlib.contextmanager\n","# def _set_default_tensor_type(dtype: torch.dtype):\n","#   \"\"\"Sets the default torch dtype to the given dtype.\"\"\"\n","#   torch.set_default_dtype(dtype)\n","#   yield\n","#   torch.set_default_dtype(torch.float)\n","\n","# model_config = get_config_for_2b() if \"2b\" in VARIANT else get_config_for_7b()\n","# model_config.tokenizer = os.path.join(weights_dir, \"tokenizer.model\")\n","\n","# device = torch.device(MACHINE_TYPE)\n","# with _set_default_tensor_type(model_config.get_dtype()):\n","#   model = GemmaForCausalLM(model_config)\n","#   ckpt_path = os.path.join(weights_dir, f'gemma-{VARIANT}.ckpt')\n","#   model.load_weights(ckpt_path)\n","#   model = model.to(device).eval()"]},{"cell_type":"markdown","metadata":{},"source":["## Load 7B-it-quant Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load the model\n","VARIANT = \"7b-it-quant\" \n","MACHINE_TYPE = \"cuda\" \n","weights_dir = f'gemma-{VARIANT}-weights' \n","\n","@contextlib.contextmanager\n","def _set_default_tensor_type(dtype: torch.dtype):\n","  \"\"\"Sets the default torch dtype to the given dtype.\"\"\"\n","  torch.set_default_dtype(dtype)\n","  yield\n","  torch.set_default_dtype(torch.float)\n","\n","model_config = get_config_for_2b() if \"2b\" in VARIANT else get_config_for_7b()\n","model_config.tokenizer = os.path.join(weights_dir, \"tokenizer.model\")\n","model_config.quant = \"quant\" in VARIANT\n","\n","device = torch.device(MACHINE_TYPE)\n","with _set_default_tensor_type(model_config.get_dtype()):\n","  model = GemmaForCausalLM(model_config)\n","  ckpt_path = os.path.join(weights_dir, f'gemma-{VARIANT}.ckpt')\n","  model.load_weights(ckpt_path)\n","  model = model.to(device).eval()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["PATH_TO_DATASET = 'gen_data.xlsx'\n","df = pd.read_csv(PATH_TO_DATASET)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_template = \"<start_of_turn>user\\n{rewrite_prompt}\\n{original_text}<end_of_turn>\\n<start_of_turn>model\\nRewritten Text: ```\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rewrite_data = {\n","    'original_text': [],\n","    'rewrite_prompt': [] ,\n","    'rewritten_text': [],\n","}\n","BATCH_SIZE = 2\n","\n","def check_newline(text):\n","    if text[:2] == '\\n':\n","        text = text[2:]\n","    \n","    if text[-2:] == '\\n':\n","        text = text[:-2]\n","    \n","    return text\n","    \n","prompts = []\n","orig_text = []\n","rewrite_prompts = []\n","for i, (original_text, rewrite_prompt) in enumerate(zip(df.text.values, df.prompt.values), start = 1):\n","    prompts.append(new_template.format(rewrite_prompt=rewrite_prompt, original_text=original_text))\n","    orig_text.append(original_text)\n","    rewrite_prompts.append(rewrite_prompt)\n","    if i % BATCH_SIZE == 0 or i == len(df)-1:\n","        print(\"processing prompts from {} to {}\".format(i-BATCH_SIZE+1, i))\n","        rewritten_text = model.generate(\n","            prompts,\n","            device=device,\n","            output_len=300,\n","        )\n","        rewritten_text = [x.split('```')[0].strip() for x in rewritten_text]\n","        rewritten_text = [check_newline(x) for x in rewritten_text]\n","        rewrite_data['original_text'].extend(orig_text)\n","        rewrite_data['rewrite_prompt'].extend(rewrite_prompts)\n","        rewrite_data['rewritten_text'].extend(rewritten_text)\n","        torch.cuda.empty_cache()\n","        prompts = []\n","        orig_text = []\n","        rewrite_prompts = []\n","\n","if len(prompts) > 0:\n","    print(\"processing prompts from {} to {}\".format(i-BATCH_SIZE+1, i))\n","    rewritten_text = model.generate(\n","        prompts,\n","        device=device,\n","        output_len=300,\n","    )\n","    rewritten_text = [x.split('```')[0].strip() for x in rewritten_text]\n","    rewritten_text = [check_newline(x) for x in rewritten_text]\n","    rewrite_data['original_text'].extend(orig_text)\n","    rewrite_data['rewrite_prompt'].extend(rewrite_prompts)\n","    rewrite_data['rewritten_text'].extend(rewritten_text)\n","    torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rewrite_data_df = pd.DataFrame(rewrite_data)\n","rewrite_data_df[:1].values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rewrite_data_df.to_excel('dataset.xlsx', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7806901,"sourceId":67121,"sourceType":"competition"},{"databundleVersionId":7771678,"modelInstanceId":5388,"sourceId":11372,"sourceType":"modelInstanceVersion"},{"databundleVersionId":7771679,"modelInstanceId":5391,"sourceId":11373,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":4}
